{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ede548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shasw\\anaconda3\\envs\\MediBotics\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcf1bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from pdf\n",
    "def load_file(data):\n",
    "    loader=DirectoryLoader(data,glob=\"*.pdf\",loader_cls=PyPDFLoader)\n",
    "    doc=loader.load()\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb9a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_pdf=load_file(data='Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d640396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af810562",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_documents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chunks\u001b[38;5;241m=\u001b[39m\u001b[43mprocess_documents\u001b[49m(data_from_pdf)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_documents' is not defined"
     ]
    }
   ],
   "source": [
    "chunks=process_documents(data_from_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719083a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79ba52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_embeddings():\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a098b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = download_hugging_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "610796ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f432f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv('Pinecone_API_Key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "270e20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc=Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name=\"medibotics\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\",\n",
    "                            region=\"us-east-1\"\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "728af430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"Pinecone_API_Key\"]=PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10ce5b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shasw\\anaconda3\\envs\\MediBotics\\lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5b1592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad864227",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=docsearch.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9014fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs=retriever.invoke(\"What is diabetes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dce7c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_2_0_FLASH_API_KEY = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87d0f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_2_0_FLASH_API_KEY\"]=\"GOOGLE_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f21a6cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm=ChatGoogleGenerativeAI( model=\"gemini-1.5-flash\",temperature=0,max_output_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f52ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt=(\n",
    "    \"You are an assistant for question-answering tasks.\"\n",
    "    \"Use the following pieces of retrived context to answer\"\n",
    "    \"the questions. If you don't know the answer , say that you\"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt= ChatPromptTemplate.from_messages([\n",
    "    (\"system\",system_prompt),\n",
    "    (\"user\",\"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11f69f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer=create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain=create_retrieval_chain(retriever,question_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2232ed36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I cannot answer this question.  The provided text focuses on intelligence testing and Wegener's granulomatosis; it does not define or explain statistics.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke({\"input\":\"What is Stats?\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MediBotics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
